<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Point Transformer v2: Architecture and Implementation Details | Antoine Ach </title> <meta name="author" content="Antoine Ach"> <meta name="description" content="Detailed analysis of the Point Transformer v2 architecture for point-cloud segmentation and classification"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="http://antoineach.github.io//blog/2025/pointTransformerv2/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Antoine</span> Ach </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Point Transformer v2: Architecture and Implementation Details</h1> <p class="post-meta"> Created on October 26, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/point-cloud"> <i class="fa-solid fa-hashtag fa-sm"></i> point-cloud</a>   <a href="/blog/tag/transformer"> <i class="fa-solid fa-hashtag fa-sm"></i> transformer</a>   <a href="/blog/tag/architecture"> <i class="fa-solid fa-hashtag fa-sm"></i> architecture</a>   ·   <a href="/blog/category/computer-vision"> <i class="fa-solid fa-tag fa-sm"></i> computer-vision</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="point-transformer-v2-architecture-et-améliorations">Point Transformer v2: Architecture et Améliorations</h1> <h2 id="introduction">Introduction</h2> <p><strong>Point Transformer v2</strong> améliore significativement son prédécesseur en termes d’efficacité computationnelle et de performances. Les innovations clés incluent :</p> <ul> <li> <strong>Grid Pooling</strong> au lieu de Furthest Point Sampling (3-5× plus rapide)</li> <li> <strong>Map Unpooling</strong> qui réutilise l’information du downsampling</li> <li> <strong>GroupedLinear</strong> pour réduire drastiquement le nombre de paramètres</li> <li> <strong>Attention vectorielle enrichie</strong> avec encodage de position sur les values</li> <li> <strong>Masking des voisins invalides</strong> pour gérer les nuages de tailles variables</li> </ul> <p>Avant de plonger dans l’architecture globale, commençons par comprendre deux innovations fondamentales : GroupedLinear et GroupedVectorAttention.</p> <hr> <h2 id="architecture-globale">Architecture Globale</h2> <figure> <picture> <img src="/assets/img/poinTransformerv2/architecture.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>PTv2 suit une architecture U-Net avec :</p> <p><strong>Encodeur (Downsampling):</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input (N points, in_channels)
    ↓ GVAPatchEmbed
N points, 48 channels
    ↓ Encoder 1 (GridPool)
N1 points, 96 channels
    ↓ Encoder 2 (GridPool)
N2 points, 192 channels
    ↓ Encoder 3 (GridPool)
N3 points, 384 channels
    ↓ Encoder 4 (GridPool)
N4 points, 512 channels [BOTTLENECK]
</code></pre></div></div> <p><strong>Décodeur (Upsampling):</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>N4 points, 512 channels
    ↓ Decoder 4 (Unpool + skip)
N3 points, 384 channels
    ↓ Decoder 3 (Unpool + skip)
N2 points, 192 channels
    ↓ Decoder 2 (Unpool + skip)
N1 points, 96 channels
    ↓ Decoder 1 (Unpool + skip)
N points, 48 channels
    ↓ Segmentation Head
N points, num_classes
</code></pre></div></div> <p><strong>Points clés:</strong></p> <ul> <li>Chaque <strong>Encoder</strong> réduit le nombre de points via <strong>GridPool</strong> (voxelisation)</li> <li>Chaque <strong>Decoder</strong> remonte en résolution via <strong>Map Unpooling</strong> + skip connection</li> <li>Les <strong>clusters</strong> stockent le mapping de voxelisation pour l’unpooling</li> <li> <strong>Pas de Furthest Point Sampling</strong> → beaucoup plus rapide !</li> </ul> <hr> <h2 id="groupedlinear--réduction-paramétrique-intelligente">GroupedLinear : Réduction Paramétrique Intelligente</h2> <h3 id="le-problème-avec-linear-classique">Le problème avec Linear classique</h3> <p>Dans un réseau profond, générer des poids d’attention via des couches Linear standard accumule rapidement des paramètres :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Linear classique pour générer 8 poids d'attention depuis 64 features
</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="c1"># Paramètres: 64 × 8 = 512 poids + 8 biais = 520 paramètres
</span></code></pre></div></div> <h3 id="linnovation-groupedlinear">L’innovation GroupedLinear</h3> <figure> <picture> <img src="/assets/img/poinTransformerv2/groupedLinear.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>GroupedLinear</strong> remplace la matrice de poids par un <strong>vecteur de poids partagé</strong> :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GroupedLinear
</span><span class="n">weight</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>  <span class="c1"># UN SEUL vecteur au lieu d'une matrice
# Paramètres: 64 (pas de biais)
</span></code></pre></div></div> <h3 id="fonctionnement-étape-par-étape">Fonctionnement étape par étape</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
    <span class="c1"># input: (N, in_features) = (N, 64)
</span>    <span class="c1"># weight: (1, in_features) = (1, 64)
</span>    
    <span class="c1"># Étape 1: Multiplication élément par élément
</span>    <span class="n">temp</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">*</span> <span class="n">weight</span>  <span class="c1"># (N, in_features)
</span>    
    <span class="c1"># Étape 2: Reshape en groupes
</span>    <span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">in_features</span><span class="o">/</span><span class="n">groups</span><span class="p">)</span>
    <span class="c1"># temp: (N, groups, in_features/groups)
</span>    
    <span class="c1"># Étape 3: Somme par groupe
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, groups) = (N, out_features)
</span>    
    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div> <h3 id="exemple-numérique-concret">Exemple numérique concret</h3> <p>Prenons <strong>N=1, in_features=8, groups=out_features=4</strong> pour simplifier :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Input
</span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># (8,)
</span>
<span class="c1"># Weight (vecteur partagé)
</span><span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>  <span class="c1"># (8,)
</span>
<span class="c1"># Étape 1: Multiplication élément par élément
</span><span class="n">temp</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="err">×</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">3</span><span class="err">×</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">1</span><span class="err">×</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">4</span><span class="err">×</span><span class="mf">0.8</span><span class="p">,</span> <span class="mi">5</span><span class="err">×</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">2</span><span class="err">×</span><span class="mf">0.9</span><span class="p">,</span> <span class="mi">3</span><span class="err">×</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">1</span><span class="err">×</span><span class="mf">0.7</span><span class="p">]</span>
     <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>

<span class="c1"># Étape 2: Reshape en 4 groupes de 2 dimensions
</span><span class="n">temp_grouped</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>     <span class="c1"># Groupe 0
</span>    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">],</span>     <span class="c1"># Groupe 1
</span>    <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">],</span>     <span class="c1"># Groupe 2
</span>    <span class="p">[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>      <span class="c1"># Groupe 3
</span><span class="p">]</span>

<span class="c1"># Étape 3: Somme par groupe
</span><span class="n">output</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">3.0</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>    <span class="c1"># Groupe 0
</span>    <span class="mf">0.2</span> <span class="o">+</span> <span class="mf">3.2</span> <span class="o">=</span> <span class="mf">3.4</span><span class="p">,</span>    <span class="c1"># Groupe 1
</span>    <span class="mf">1.5</span> <span class="o">+</span> <span class="mf">1.8</span> <span class="o">=</span> <span class="mf">3.3</span><span class="p">,</span>    <span class="c1"># Groupe 2
</span>    <span class="mf">1.2</span> <span class="o">+</span> <span class="mf">0.7</span> <span class="o">=</span> <span class="mf">1.9</span>     <span class="c1"># Groupe 3
</span><span class="p">]</span>
<span class="c1"># Résultat: [4.0, 3.4, 3.3, 1.9]
</span></code></pre></div></div> <h3 id="comparaison-des-paramètres">Comparaison des paramètres</h3> <table> <thead> <tr> <th>Configuration</th> <th>Linear classique</th> <th>GroupedLinear</th> <th>Réduction</th> </tr> </thead> <tbody> <tr> <td>64 → 8</td> <td>64×8 = <strong>512</strong> </td> <td><strong>64</strong></td> <td>8×</td> </tr> <tr> <td>128 → 16</td> <td>128×16 = <strong>2048</strong> </td> <td><strong>128</strong></td> <td>16×</td> </tr> <tr> <td>256 → 32</td> <td>256×32 = <strong>8192</strong> </td> <td><strong>256</strong></td> <td>32×</td> </tr> </tbody> </table> <h2 id="groupedlinear-force-le-modèle-à-utiliser-les-mêmes-poids-pour-tous-les-groupes-mais-appliqués-sur-des-portions-différentes-de-linput">GroupedLinear force le modèle à utiliser les mêmes poids pour tous les groupes, mais appliqués sur des portions différentes de l’input.</h2> <h2 id="groupedvectorattention--attention-locale-enrichie">GroupedVectorAttention : Attention Locale Enrichie</h2> <h3 id="vue-densemble">Vue d’ensemble</h3> <p><code class="language-plaintext highlighter-rouge">GroupedVectorAttention</code> est le cœur de PTv2, avec plusieurs améliorations par rapport à PTv1.</p> <figure> <picture> <img src="/assets/img/poinTransformerv2/groupedVectorAttention.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="comparaison-détaillée-avec-ptv1">Comparaison détaillée avec PTv1</h3> <table> <thead> <tr> <th>Aspect</th> <th>PTv1 (PointTransformerLayer)</th> <th>PTv2 (GroupedVectorAttention)</th> </tr> </thead> <tbody> <tr> <td><strong>Projections Q, K, V</strong></td> <td>Simple Linear</td> <td>Linear + <strong>BatchNorm1d + ReLU</strong> </td> </tr> <tr> <td><strong>Position Encoding</strong></td> <td>Additif uniquement</td> <td>Additif (+ option multiplicatif)</td> </tr> <tr> <td><strong>Position Encoding sur values</strong></td> <td>❌ Non</td> <td>✅ <strong>Oui</strong> </td> </tr> <tr> <td><strong>Masking voisins invalides</strong></td> <td>❌ Non (assume tous valides)</td> <td>✅ <strong>Oui</strong> </td> </tr> <tr> <td><strong>Weight generation</strong></td> <td>MLP standard (C×C/G params)</td> <td> <strong>GroupedLinear</strong> (C params seulement)</td> </tr> <tr> <td><strong>Normalisation</strong></td> <td>Après weight encoding</td> <td> <strong>Avant et après</strong> attention</td> </tr> </tbody> </table> <h3 id="innovation-1--normalisation-des-projections-q-k-v">Innovation 1 : Normalisation des Projections Q, K, V</h3> <p><strong>PTv1 :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Projections simples sans normalisation
</span><span class="n">self</span><span class="p">.</span><span class="n">linear_q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">mid_planes</span><span class="p">)</span>
<span class="n">self</span><span class="p">.</span><span class="n">linear_k</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">mid_planes</span><span class="p">)</span>
<span class="n">self</span><span class="p">.</span><span class="n">linear_v</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">)</span>

<span class="c1"># Usage
</span><span class="n">query</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_q</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>  <span class="c1"># (N, C)
</span><span class="n">key</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_k</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>    <span class="c1"># (N, C)
</span><span class="n">value</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_v</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>  <span class="c1"># (N, C)
</span></code></pre></div></div> <p><strong>PTv2 :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Projections avec normalisation et activation
</span><span class="n">self</span><span class="p">.</span><span class="n">linear_q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">embed_channels</span><span class="p">,</span> <span class="n">embed_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">),</span>
    <span class="nc">PointBatchNorm</span><span class="p">(</span><span class="n">embed_channels</span><span class="p">),</span>  <span class="c1"># Normalisation !
</span>    <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>            <span class="c1"># Activation !
</span><span class="p">)</span>
<span class="c1"># Idem pour linear_k
</span>
<span class="c1"># Usage
</span><span class="n">query</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_q</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>  <span class="c1"># (N, C) - normalisé et activé
</span></code></pre></div></div> <p><strong>Pourquoi c’est important ?</strong></p> <p>La normalisation des Q, K stabilise l’entraînement en évitant des valeurs extrêmes dans la relation Q-K :</p> <p><strong>Impact :</strong> Convergence plus rapide et training plus stable.</p> <hr> <h3 id="innovation-2--position-encoding-sur-les-values">Innovation 2 : Position Encoding sur les Values</h3> <p><strong>PTv1 :</strong> L’encodage de position n’est ajouté qu’à la relation Q-K</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Code PTv1 (simplifié)
</span><span class="n">relative_positions</span> <span class="o">=</span> <span class="n">neighbor_positions</span> <span class="o">-</span> <span class="n">query_position</span>  <span class="c1"># (N, K, 3)
</span><span class="n">encoded_positions</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">relative_positions</span><span class="p">)</span>               <span class="c1"># (N, K, out_dim)
</span>
<span class="c1"># Application UNIQUEMENT sur relation Q-K
</span><span class="n">relation_qk</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span> <span class="o">-</span> <span class="n">query</span><span class="p">)</span> <span class="o">+</span> <span class="n">encoded_positions</span>
<span class="c1"># Les values ne sont PAS modifiées par la géométrie
</span>
</code></pre></div></div> <p><strong>PTv2 :</strong> L’encodage est ajouté à la relation Q-K <strong>ET aux values</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Code PTv2
</span><span class="n">pe_bias</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">relative_positions</span><span class="p">)</span>  <span class="c1"># (N, K, C)
</span>
<span class="c1"># Sur la relation Q-K (comme PTv1)
</span><span class="n">relation_qk</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span> <span class="o">-</span> <span class="n">query</span><span class="p">)</span> <span class="o">+</span> <span class="n">pe_bias</span>

<span class="c1"># NOUVEAU: aussi sur les values !
</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span> <span class="o">+</span> <span class="n">pe_bias</span>

<span class="c1"># (values contiennent maintenant l'info géométrique)
</span></code></pre></div></div> <h3 id="innovation-3--masking-des-voisins-invalides">Innovation 3 : Masking des Voisins Invalides</h3> <p><strong>Contexte : Différence Fondamentale entre PTv1 et PTv2</strong></p> <h4 id="ptv1--k-nn-garantit-toujours-k-voisins">PTv1 : K-NN garantit toujours K voisins</h4> <p>Dans PTv1, les voisins sont trouvés via <strong>K-Nearest Neighbors (K-NN)</strong> :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv1 - Dans chaque PointTransformerLayer
</span><span class="n">x_k</span> <span class="o">=</span> <span class="n">pointops</span><span class="p">.</span><span class="nf">queryandgroup</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">nsample</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">x_k</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">use_xyz</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># Retourne TOUJOURS exactement K voisins (via K-NN search)
</span></code></pre></div></div> <p><strong>PTv1 n’a donc pas besoin de masking</strong> : tous les K voisins sont valides (même si certains peuvent être très éloignés).</p> <hr> <h4 id="ptv2--grid-pooling-peut-avoir--k-voisins">PTv2 : Grid Pooling peut avoir &lt; K voisins</h4> <p>Dans PTv2, les voisins sont déterminés par <strong>Grid Pooling</strong> (voxelisation), qui peut créer des régions avec moins de K points.</p> <p><strong>Rappel : Qu’est-ce que le Grid Pooling ?</strong></p> <p>Le <strong>Grid Pooling</strong> partitionne l’espace en <strong>voxels</strong> (cubes 3D de taille <code class="language-plaintext highlighter-rouge">grid_size</code>) et agrège tous les points d’un même voxel :</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Avant Grid Pooling (N=16 points):

        grid_size = 0.5m
      
            ┌─────┬─────┬─────┬─────┐
            │ ●●  │     │  ●  │     │
            │ ●   │     │     │     │
            ├─────┼─────┼─────┼─────┤
            │  ●  │ ●●  │     │     │
            │     │  ●  │     │     │
            ├─────┼─────┼─────┼─────┤
            │     │  ●  │ ●   │  ●  │
            │  ●  │     │   ● │     │
            ├─────┼─────┼─────┼─────┤
            │  ●  │     │     │     │
            │     │  ●  │  ●  │     │
            └─────┴─────┴─────┴─────┘

Après Grid Pooling (M=10 voxels):
    
    ┌─────┬─────┬─────┬─────┐
    │  ◉ │     │  ◉  │     │  ← 1 point par voxel occupé
    │     │     │     │     │
    ├─────┼─────┼─────┼─────┤
    │  ◉  │  ◉  │     │     │
    │     │     │     │     │
    ├─────┼─────┼─────┼─────┤
    │  ◉  │  ◉  │  ◉  │  ◉  │
    │     │     │     │     │
    ├─────┼─────┼─────┼─────┤
    │  ◉  │  ◉  │     │     │
    │     │     │     │     │
    └─────┴─────┴─────┴─────┘
</code></pre></div></div> <p><strong>Conséquence :</strong> Après Grid Pooling, certaines zones peuvent être <strong>peu denses</strong> :</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Configuration: K=8 voisins demandés

Zone dense:                   Zone peu dense (bord du nuage):
    ◉  ◉  ◉                       ◉
    ◉  ●  ◉                          
    ◉  ◉  ◉                               ◉
    
Point ● a 8 voisins ✓         Point ◉ a seulement 2 voisins ✗
</code></pre></div></div> <p><strong>Comment PTv2 gère-t-il le manque de voisins ?</strong></p> <p>Lors du K-NN sur les voxels poolés, si un voxel a moins de K voisins disponibles, les indices manquants sont marqués par <strong>-1</strong> :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv2 - K-NN sur les voxels après Grid Pooling
</span><span class="n">reference_index</span> <span class="o">=</span> <span class="nf">knn_query</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">coord_pooled</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
<span class="c1"># reference_index: (M, K)
</span>
<span class="c1"># Exemple pour un voxel isolé
</span><span class="n">reference_index</span><span class="p">[</span><span class="n">voxel_42</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1">#                            ↑───↑   ↑──────────────────────↑
#                            2 voisins    6 indices invalides (-1)
</span></code></pre></div></div> <p><strong>Pourquoi -1 et pas juste moins d’indices ?</strong></p> <p>Pour garder une <strong>shape uniforme</strong> <code class="language-plaintext highlighter-rouge">(M, K)</code> compatible avec les opérations matricielles :</p> <ul> <li>Tous les tensors ont la même forme</li> <li>Permet le batching efficace sur GPU</li> <li>Le padding avec -1 permet le masking explicite</li> </ul> <hr> <p><strong>Solution PTv2 : Masking Explicite</strong></p> <p><strong>Étape 1 : Création du masque</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># reference_index contient -1 pour les voisins invalides
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sign</span><span class="p">(</span><span class="n">reference_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (M, K)
</span>
<span class="c1"># Comportement de sign(x+1):
# Si reference_index[i] = -1  → sign(-1+1) = sign(0) = 0  ← invalide
# Si reference_index[i] ≥ 0   → sign(≥1) = 1             ← valide
</span></code></pre></div></div> <p><strong>Étape 2 : Application sur les poids d’attention</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dans GroupedVectorAttention, après softmax
</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">)</span>  <span class="c1"># (M, K, groups)
</span>
<span class="c1"># Application du masque
</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention_weights</span> <span class="o">*</span> <span class="n">mask</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Shape: (M, K, groups) × (M, K, 1) → (M, K, groups)
</span></code></pre></div></div> <p><strong>Visualisation :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Avant masking (après softmax sur K voisins)
</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">voxel_42</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">0.20</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Voisin 15 (valide)
</span>    <span class="p">[</span><span class="mf">0.18</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Voisin 23 (valide)
</span>    <span class="p">[</span><span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Padding -1 (invalide mais a des poids !)
</span>    <span class="p">[</span><span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Padding -1 (invalide)
</span>    <span class="p">[</span><span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Padding -1 (invalide)
</span>    <span class="p">[</span><span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Padding -1 (invalide)
</span>    <span class="p">[</span><span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.18</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Padding -1 (invalide)
</span>    <span class="p">[</span><span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">,</span> <span class="mf">0.17</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Padding -1 (invalide)
</span><span class="p">]</span>

<span class="c1"># Après masking
</span><span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">attention_weights</span><span class="p">[</span><span class="n">voxel_42</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">0.20</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Voisin 15 ✓
</span>    <span class="p">[</span><span class="mf">0.18</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="p">...],</span>  <span class="c1"># Voisin 23 ✓
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...],</span>            <span class="c1"># Annulé ✓
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...],</span>            <span class="c1"># Annulé ✓
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...],</span>            <span class="c1"># Annulé ✓
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...],</span>            <span class="c1"># Annulé ✓
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...],</span>            <span class="c1"># Annulé ✓
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...],</span>            <span class="c1"># Annulé ✓
</span><span class="p">]</span>
</code></pre></div></div> <p><strong>Étape 3 : Agrégation</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Agrégation finale (somme pondérée)
</span><span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">value_grouped</span> <span class="o">*</span> <span class="n">attention_weights</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)).</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Les voisins invalides (poids=0) ne contribuent pas ✓
</span></code></pre></div></div> <hr> <p><strong>Pourquoi c’est Crucial ?</strong></p> <p><strong>Sans masking</strong>, les voisins padding contribueraient avec des <strong>features aléatoires</strong> :</p> <hr> <h3 id="innovation-4--groupedlinear-pour-les-poids-dattention">Innovation 4 : GroupedLinear pour les Poids d’Attention</h3> <p>Au lieu d’un MLP standard <code class="language-plaintext highlighter-rouge">Linear(C, groups)</code> avec C×groups paramètres, PTv2 utilise <code class="language-plaintext highlighter-rouge">GroupedLinear(C, groups)</code> avec seulement C paramètres.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv1: MLP standard
</span><span class="n">self</span><span class="p">.</span><span class="n">linear_w</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">mid_planes</span><span class="p">,</span> <span class="n">mid_planes</span> <span class="o">//</span> <span class="n">share_planes</span><span class="p">),</span>  <span class="c1"># C × C/G paramètres
</span>    <span class="bp">...</span>
<span class="p">)</span>

<span class="c1"># PTv2: avec GroupedLinear
</span><span class="n">self</span><span class="p">.</span><span class="n">weight_encoding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
    <span class="nc">GroupedLinear</span><span class="p">(</span><span class="n">embed_channels</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">groups</span><span class="p">),</span>  <span class="c1"># Seulement C paramètres !
</span>    <span class="bp">...</span>
<span class="p">)</span>
</code></pre></div></div> <p><strong>Gain :</strong> moins de paramètres pour générer les poids d’attention, sans perte de performance.</p> <h3 id="innovation-5--architecture-de-normalisation">Innovation 5 : Architecture de Normalisation</h3> <p><strong>PTv1 :</strong> Normalisation minimale</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv1 - Pas de normalisation sur les projections Q, K, V
</span><span class="n">query</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Pas normalisé
</span><span class="n">key</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Normalisation seulement dans le MLP des poids
</span><span class="n">attention_scores</span> <span class="o">=</span> <span class="nc">MLP_with_BatchNorm</span><span class="p">(</span><span class="n">relation_qk</span><span class="p">)</span>
</code></pre></div></div> <p><strong>PTv2 :</strong> Normalisation extensive</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv2 - Normalisation partout
</span><span class="n">query</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span>  <span class="c1"># Normalisé
</span><span class="n">key</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span>
<span class="n">value</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Pas d'activation (reste linéaire)
</span>
<span class="c1"># Position encoding aussi normalisé
</span><span class="n">pe_bias</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span> <span class="err">→</span> <span class="n">Linear</span>

<span class="c1"># Weight encoding aussi normalisé
</span><span class="n">attention_scores</span> <span class="o">=</span> <span class="n">GroupedLinear</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span> <span class="err">→</span> <span class="n">Linear</span>
</code></pre></div></div> <p><strong>Impact :</strong> Training plus stable, convergence plus rapide, moins sensible aux hyperparamètres.</p> <hr> <h1 id="block-et-blocksequence--architecture-résiduelle">Block et BlockSequence : Architecture Résiduelle</h1> <h2 id="block--residual-block-avec-droppath">Block : Residual Block avec DropPath</h2> <p>Le <code class="language-plaintext highlighter-rouge">Block</code> de PTv2 encapsule <code class="language-plaintext highlighter-rouge">GroupedVectorAttention</code> dans une structure résiduelle similaire à ResNet, avec une innovation clé : <strong>DropPath</strong>.</p> <figure> <picture> <img src="/assets/img/poinTransformerv2/block.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="comparaison-avec-ptv1">Comparaison avec PTv1</h3> <table> <thead> <tr> <th>Aspect</th> <th>PTv1 (PointTransformerBlock)</th> <th>PTv2 (Block)</th> </tr> </thead> <tbody> <tr> <td><strong>Structure</strong></td> <td>Linear → Attention → Linear + Skip</td> <td>Linear → Attention → Linear + Skip</td> </tr> <tr> <td><strong>Régularisation</strong></td> <td>Dropout uniquement</td> <td> <strong>DropPath</strong> + Dropout</td> </tr> <tr> <td><strong>Normalisation</strong></td> <td>3× BatchNorm</td> <td>3× BatchNorm (identique)</td> </tr> <tr> <td><strong>Skip connection</strong></td> <td>Simple addition</td> <td>Addition avec <strong>DropPath</strong> </td> </tr> </tbody> </table> <h3 id="architecture-détaillée">Architecture Détaillée</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input features (N, C)
    ↓
[Linear + BatchNorm1d + ReLU]  ← Pre-activation (expansion)
    ↓
[GroupedVectorAttention]  ← Attention locale sur K voisins
    ↓
[BatchNorm1d + ReLU]  ← Post-attention normalization
    ↓
[Linear + BatchNorm1d]  ← Projection
    ↓
[DropPath]  ← Régularisation stochastique (NOUVEAU)
    ↓
[+ Skip Connection]  ← Connexion résiduelle
    ↓
[ReLU]  ← Activation finale
    ↓
Output features (N, C)
</code></pre></div></div> <h3 id="droppath--stochastic-depth">DropPath : Stochastic Depth</h3> <p><strong>DropPath</strong> (Stochastic Depth) est une technique de régularisation qui <strong>dropout des chemins entiers</strong> dans un réseau résiduel, plutôt que des neurones individuels.</p> <p><strong>Dropout classique vs DropPath :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dropout classique (agit sur les features)
</span><span class="k">def</span> <span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="nf">random</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">p</span>  <span class="c1"># Masque aléatoire par élément
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">mask</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="nf">dropout</span><span class="p">(</span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="c1"># Certaines features de f(x) sont mises à 0
</span>

<span class="c1"># DropPath (agit sur le chemin entier)
</span><span class="k">def</span> <span class="nf">drop_path</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>  <span class="c1"># Tout le chemin est ignoré !
</span>    <span class="k">return</span> <span class="n">x</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="nf">drop_path</span><span class="p">(</span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="c1"># Soit tout f(x) est gardé, soit tout est ignoré
</span></code></pre></div></div> <p><strong>Fonctionnement en pratique :</strong></p> <p>Durant l’entraînement, avec probabilité <code class="language-plaintext highlighter-rouge">drop_path_rate</code> (typiquement 0.1), on saute complètement le bloc transformé :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sans DropPath (PTv1)
</span><span class="n">feat_transformed</span> <span class="o">=</span> <span class="n">Linear</span> <span class="err">→</span> <span class="n">Attention</span> <span class="err">→</span> <span class="n">Linear</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">identity</span> <span class="o">+</span> <span class="n">feat_transformed</span>  <span class="c1"># Toujours calculé
</span>
<span class="c1"># Avec DropPath (PTv2)
</span><span class="n">feat_transformed</span> <span class="o">=</span> <span class="n">Linear</span> <span class="err">→</span> <span class="n">Attention</span> <span class="err">→</span> <span class="n">Linear</span>

<span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">drop_path_rate</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">identity</span>  <span class="c1"># On saute feat_transformed complètement !
</span><span class="k">else</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">identity</span> <span class="o">+</span> <span class="n">feat_transformed</span>

<span class="c1"># À l'inférence
</span><span class="n">output</span> <span class="o">=</span> <span class="n">identity</span> <span class="o">+</span> <span class="n">feat_transformed</span>  <span class="c1"># Toujours actif
</span></code></pre></div></div> <p><strong>Visualisation sur un réseau de 12 blocs :</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Avec drop_path_rate = 0.1 (10% de chance de drop par bloc)

Training iteration 1:
Input → [Block1] → [Block2] → [SKIP] → [Block4] → ... → [SKIP] → [Block12]
        ✓          ✓          ✗          ✓              ✗          ✓
        (réseau de ~10 blocs actifs)

Training iteration 2:
Input → [Block1] → [SKIP] → [Block3] → [Block4] → ... → [Block11] → [Block12]
        ✓          ✗        ✓          ✓                  ✓          ✓
        (réseau de ~11 blocs actifs)

Inference:
Input → [Block1] → [Block2] → [Block3] → [Block4] → ... → [Block11] → [Block12]
        ✓          ✓          ✓          ✓                  ✓          ✓
        (tous les 12 blocs actifs)
</code></pre></div></div> <p><strong>Cependant, dans PTv2, le <code class="language-plaintext highlighter-rouge">drop_path_rate</code> est implémenté mais laissé à 0.0. Autrement dit, il n’est pas utilisé.</strong></p> <h2 id="blocksequence--réutilisation-du-k-nn">BlockSequence : Réutilisation du K-NN</h2> <p><code class="language-plaintext highlighter-rouge">BlockSequence</code> empile plusieurs <code class="language-plaintext highlighter-rouge">Block</code> et introduit une optimisation majeure : <strong>partage du reference_index</strong>.</p> <figure> <picture> <img src="/assets/img/poinTransformerv2/blockSequence.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="innovation-clé--k-nn-calculé-une-seule-fois">Innovation Clé : K-NN Calculé Une Seule Fois</h3> <p><strong>Problème PTv1 :</strong></p> <p>Dans PTv1, chaque <code class="language-plaintext highlighter-rouge">PointTransformerLayer</code> recalcule les K plus proches voisins via K-NN :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv1 - Dans PointTransformerLayer.forward()
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">pxo</span><span class="p">):</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">o</span> <span class="o">=</span> <span class="n">pxo</span>
    
    <span class="c1"># K-NN calculé À CHAQUE COUCHE
</span>    <span class="n">x_k</span> <span class="o">=</span> <span class="n">pointops</span><span class="p">.</span><span class="nf">queryandgroup</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">nsample</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">x_k</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">use_xyz</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">x_v</span> <span class="o">=</span> <span class="n">pointops</span><span class="p">.</span><span class="nf">queryandgroup</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">nsample</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">x_v</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">use_xyz</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="c1"># ...
</span></code></pre></div></div> <p>Pour un bloc avec 6 couches <code class="language-plaintext highlighter-rouge">PointTransformerLayer</code>, on fait <strong>6 fois</strong> la même recherche K-NN !</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Bloc avec 6 couches PTv1:
Layer 1: K-NN (N points, find K=16 neighbors) → O(N log N)
Layer 2: K-NN (N points, find K=16 neighbors) → O(N log N)
Layer 3: K-NN (N points, find K=16 neighbors) → O(N log N)
Layer 4: K-NN (N points, find K=16 neighbors) → O(N log N)
Layer 5: K-NN (N points, find K=16 neighbors) → O(N log N)
Layer 6: K-NN (N points, find K=16 neighbors) → O(N log N)

Coût total: 6 × O(N log N)
</code></pre></div></div> <p><strong>Solution PTv2 :</strong></p> <p>Dans PTv2, <code class="language-plaintext highlighter-rouge">BlockSequence</code> calcule le K-NN <strong>une seule fois</strong> au début et tous les <code class="language-plaintext highlighter-rouge">Block</code> partagent le même <code class="language-plaintext highlighter-rouge">reference_index</code> :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv2 - Dans BlockSequence.forward()
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="n">coord</span><span class="p">,</span> <span class="n">feat</span><span class="p">,</span> <span class="n">offset</span> <span class="o">=</span> <span class="n">points</span>
    
    <span class="c1"># K-NN calculé UNE SEULE FOIS au début
</span>    <span class="n">reference_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pointops</span><span class="p">.</span><span class="nf">knn_query</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">neighbours</span><span class="p">,</span> <span class="n">coord</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
    <span class="c1"># reference_index: (N, K) - indices des K voisins pour chaque point
</span>    
    <span class="c1"># Tous les blocks partagent le même reference_index
</span>    <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">blocks</span><span class="p">:</span>
        <span class="n">points</span> <span class="o">=</span> <span class="nf">block</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">reference_index</span><span class="p">)</span>  <span class="c1"># Pas de recalcul !
</span>    
    <span class="k">return</span> <span class="n">points</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Bloc avec 6 couches PTv2:
K-NN (une fois): O(N log N)
Layer 1: Utilise reference_index → O(1) lookup
Layer 2: Utilise reference_index → O(1) lookup
Layer 3: Utilise reference_index → O(1) lookup
Layer 4: Utilise reference_index → O(1) lookup
Layer 5: Utilise reference_index → O(1) lookup
Layer 6: Utilise reference_index → O(1) lookup

Coût total: O(N log N)  ← 6× plus rapide !
</code></pre></div></div> <h3 id="pourquoi-cest-valide-">Pourquoi c’est Valide ?</h3> <p><strong>Question :</strong> Peut-on vraiment réutiliser les mêmes voisins à travers toutes les couches ?</p> <p><strong>Réponse :</strong> <strong>OUI</strong>, car dans <code class="language-plaintext highlighter-rouge">BlockSequence</code>, les <strong>positions ne changent pas</strong> !</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dans Block.forward()
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">reference_index</span><span class="p">):</span>
    <span class="n">coord</span><span class="p">,</span> <span class="n">feat</span><span class="p">,</span> <span class="n">offset</span> <span class="o">=</span> <span class="n">points</span>
    
    <span class="c1"># coord (positions) reste INCHANGÉ à travers le bloc
</span>    <span class="n">feat</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>  <span class="c1"># Seulement les features changent
</span>    <span class="n">feat</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">attn</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">coord</span><span class="p">,</span> <span class="n">reference_index</span><span class="p">)</span>  <span class="c1"># coord fixe
</span>    <span class="n">feat</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc3</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
    <span class="c1"># ...
</span>    
    <span class="k">return</span> <span class="p">[</span><span class="n">coord</span><span class="p">,</span> <span class="n">feat</span><span class="p">,</span> <span class="n">offset</span><span class="p">]</span>  <span class="c1"># coord identique en sortie
</span></code></pre></div></div> <p>Les positions 3D (<code class="language-plaintext highlighter-rouge">coord</code>) sont <strong>constantes</strong> dans un <code class="language-plaintext highlighter-rouge">BlockSequence</code> - seules les <strong>features</strong> évoluent. Les K plus proches voisins restent donc identiques géométriquement !</p> <p><strong>Cas où on DOIT recalculer le K-NN :</strong></p> <p>Les positions changent uniquement lors des transitions entre niveaux de l’architecture (downsampling/upsampling) :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Encoder
</span><span class="n">points</span> <span class="o">=</span> <span class="nc">BlockSequence</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>  <span class="c1"># Positions fixes, K-NN partagé ✓
</span><span class="n">points</span> <span class="o">=</span> <span class="nc">GridPool</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>        <span class="c1"># Positions changent (downsampling) ✗
</span><span class="n">points</span> <span class="o">=</span> <span class="nc">BlockSequence</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>  <span class="c1"># Nouvelles positions → nouveau K-NN ✓
</span>
<span class="c1"># Decoder
</span><span class="n">points</span> <span class="o">=</span> <span class="nc">UnpoolWithSkip</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">skip</span><span class="p">)</span>  <span class="c1"># Positions changent (upsampling) ✗
</span><span class="n">points</span> <span class="o">=</span> <span class="nc">BlockSequence</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>         <span class="c1"># Nouvelles positions → nouveau K-NN ✓
</span></code></pre></div></div> <hr> <h2 id="gvapatchembed--embedding-initial">GVAPatchEmbed : Embedding Initial</h2> <p>Avant de downsampler, PTv2 applique un <code class="language-plaintext highlighter-rouge">GVAPatchEmbed</code> qui enrichit les features à pleine résolution.</p> <figure> <picture> <img src="/assets/img/poinTransformerv2/GVAPatchEmbed.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="rôle">Rôle</h3> <p><strong>GVAPatchEmbed</strong> = Projection linéaire + BlockSequence (sans downsampling)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Input</span><span class="p">:</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">)</span>
    <span class="err">↓</span>
<span class="n">Linear</span> <span class="o">+</span> <span class="n">BatchNorm1d</span> <span class="o">+</span> <span class="n">ReLU</span>
    <span class="err">↓</span>
<span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">embed_channels</span><span class="p">)</span>
    <span class="err">↓</span>
<span class="nc">BlockSequence </span><span class="p">(</span><span class="n">depth</span> <span class="n">blocks</span><span class="p">)</span>
    <span class="err">↓</span>
<span class="n">Output</span><span class="p">:</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">embed_channels</span><span class="p">)</span>
</code></pre></div></div> <h1 id="gridpool--downsampling-par-voxelisation">GridPool : Downsampling par Voxelisation</h1> <h2 id="vue-densemble-1">Vue d’ensemble</h2> <p><code class="language-plaintext highlighter-rouge">GridPool</code> est l’une des innovations majeures de PTv2, remplaçant le <strong>Furthest Point Sampling (FPS)</strong> de PTv1 par une approche basée sur la <strong>voxelisation</strong>.</p> <figure> <picture> <img src="/assets/img/poinTransformerv2/gridPool.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h4 id="voxelisation">Voxelisation</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Normalisation des coordonnées par rapport au début de chaque nuage
</span><span class="n">coord_normalized</span> <span class="o">=</span> <span class="n">coord</span> <span class="o">-</span> <span class="n">start</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>  <span class="c1"># (N, 3)
</span>
<span class="c1"># Assignation à une grille avec voxels de taille grid_size
</span><span class="n">cluster</span> <span class="o">=</span> <span class="nf">voxel_grid</span><span class="p">(</span>
    <span class="n">pos</span><span class="o">=</span><span class="n">coord_normalized</span><span class="p">,</span> 
    <span class="n">size</span><span class="o">=</span><span class="n">grid_size</span><span class="p">,</span>  <span class="c1"># ex: 0.06m
</span>    <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
    <span class="n">start</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="c1"># cluster: (N,) - ID du voxel pour chaque point
</span></code></pre></div></div> <p><strong>Exemple avec grid_size=1.0 :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Points d'un nuage (après normalisation)
</span><span class="n">points</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>  <span class="c1"># Voxel (0, 0, 0)
</span>    <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>  <span class="c1"># Voxel (0, 0, 0)
</span>    <span class="p">[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>  <span class="c1"># Voxel (1, 0, 0)
</span>    <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>  <span class="c1"># Voxel (1, 1, 0)
</span>    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>  <span class="c1"># Voxel (0, 1, 0)
</span><span class="p">]</span>

<span class="c1"># Calcul du voxel ID
</span><span class="n">voxel_id</span> <span class="o">=</span> <span class="nf">floor</span><span class="p">(</span><span class="n">coord</span> <span class="o">/</span> <span class="n">grid_size</span><span class="p">)</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">0</span><span class="p">,</span>  <span class="c1"># (0,0,0) → ID unique du voxel
</span>    <span class="mi">0</span><span class="p">,</span>  <span class="c1"># (0,0,0) → même voxel
</span>    <span class="mi">1</span><span class="p">,</span>  <span class="c1"># (1,0,0)
</span>    <span class="mi">2</span><span class="p">,</span>  <span class="c1"># (1,1,0)
</span>    <span class="mi">3</span><span class="p">,</span>  <span class="c1"># (0,1,0)
</span><span class="p">]</span>
</code></pre></div></div> <h4 id="étape-4--identification-des-voxels-uniques">Étape 4 : Identification des Voxels Uniques</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">unique</span><span class="p">,</span> <span class="n">cluster_inverse</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span>
    <span class="n">cluster</span><span class="p">,</span> 
    <span class="nb">sorted</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <p><strong>Que retourne torch.unique ?</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Input cluster (exemple)
</span><span class="n">cluster</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="c1">#          ↑─────↑  ↑──↑  ↑────────↑  ↑──────↑
#          3 pts   2 pts  4 points   3 points
</span>
<span class="n">unique</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>  <span class="c1"># Les voxels uniques
# Nvoxel = 4
</span>
<span class="n">cluster_inverse</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="c1"># Mapping: point i appartient au voxel unique[cluster_inverse[i]]
</span>
<span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>  <span class="c1"># Nombre de points par voxel
</span></code></pre></div></div> <h4 id="étape-5--tri-et-index-pointers">Étape 5 : Tri et Index Pointers</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Tri les points par voxel
</span><span class="n">_</span><span class="p">,</span> <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">cluster_inverse</span><span class="p">)</span>
<span class="c1"># sorted_indices: ordre pour regrouper les points du même voxel ensemble
</span>
<span class="c1"># Création des pointeurs pour chaque voxel
</span><span class="n">idx_ptr</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> 
    <span class="n">torch</span><span class="p">.</span><span class="nf">cumsum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="p">])</span>
<span class="c1"># idx_ptr: (Nvoxel + 1,)
</span></code></pre></div></div> <p><strong>Exemple :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Après tri
</span><span class="n">sorted_indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]</span>
<span class="c1"># Points triés par voxel
</span>
<span class="c1"># Index pointers
</span><span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">idx_ptr</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="c1">#          ↑  ↑  ↑  ↑  ↑
#          │  │  │  │  └─ Fin (12 points)
#          │  │  │  └──── Voxel 3 commence à l'indice 9
#          │  │  └─────── Voxel 2 commence à l'indice 5
#          │  └────────── Voxel 1 commence à l'indice 3
#          └───────────── Voxel 0 commence à l'indice 0
</span></code></pre></div></div> <h4 id="étape-6--agrégation-des-coordonnées-moyenne">Étape 6 : Agrégation des Coordonnées (Moyenne)</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">coord_pooled</span> <span class="o">=</span> <span class="nf">segment_csr</span><span class="p">(</span>
    <span class="n">coord</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">],</span>  <span class="c1"># Coordonnées triées par voxel
</span>    <span class="n">idx_ptr</span><span class="p">,</span> 
    <span class="nb">reduce</span><span class="o">=</span><span class="sh">"</span><span class="s">mean</span><span class="sh">"</span>
<span class="p">)</span>
<span class="c1"># coord_pooled: (Nvoxel, 3)
# Position moyenne de tous les points dans chaque voxel
</span></code></pre></div></div> <p><strong>Exemple :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Voxel 0 contient 3 points aux positions:
</span><span class="n">points_voxel_0</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">]]</span>
<span class="n">coord_pooled</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">points_voxel_0</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.37</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">]</span>

<span class="c1"># Voxel 1 contient 2 points:
</span><span class="n">points_voxel_1</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]]</span>
<span class="n">coord_pooled</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">points_voxel_1</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">]</span>
</code></pre></div></div> <h4 id="étape-7--agrégation-des-features-max">Étape 7 : Agrégation des Features (Max)</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feat_pooled</span> <span class="o">=</span> <span class="nf">segment_csr</span><span class="p">(</span>
    <span class="n">feat</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">],</span>  <span class="c1"># Features triées par voxel
</span>    <span class="n">idx_ptr</span><span class="p">,</span>
    <span class="nb">reduce</span><span class="o">=</span><span class="sh">"</span><span class="s">max</span><span class="sh">"</span>
<span class="p">)</span>
<span class="c1"># feat_pooled: (Nvoxel, out_channels)
# Maximum des features dans chaque voxel
</span></code></pre></div></div> <p><strong>Pourquoi Max au lieu de Mean ?</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Exemple avec 3 points dans un voxel
</span>
<span class="c1"># Mean pooling
</span><span class="n">feat_mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">feat1</span> <span class="o">+</span> <span class="n">feat2</span> <span class="o">+</span> <span class="n">feat3</span><span class="p">)</span> <span class="o">/</span> <span class="mi">3</span>
<span class="c1"># Peut "diluer" les features importantes
</span>
<span class="c1"># Max pooling (utilisé par PTv2)
</span><span class="n">feat_max</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">feat1</span><span class="p">,</span> <span class="n">feat2</span><span class="p">,</span> <span class="n">feat3</span><span class="p">)</span>
<span class="c1"># Préserve les features dominantes de chaque canal
# Plus robuste au bruit et aux outliers
</span></code></pre></div></div> <h4 id="étape-8--reconstruction-des-offsets">Étape 8 : Reconstruction des Offsets</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Récupération du batch ID pour chaque voxel
# (prend le batch du premier point de chaque voxel)
</span><span class="n">batch_pooled</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">idx_ptr</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
<span class="c1"># batch_pooled: (Nvoxel,)
</span>
<span class="c1"># Conversion batch → offset
</span><span class="n">offset_pooled</span> <span class="o">=</span> <span class="nf">batch2offset</span><span class="p">(</span><span class="n">batch_pooled</span><span class="p">)</span>
<span class="c1"># offset_pooled: (B,)
</span></code></pre></div></div> <h4 id="étape-9--retour-du-cluster-mapping">Étape 9 : Retour du Cluster Mapping</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">return</span> <span class="p">[</span><span class="n">coord_pooled</span><span class="p">,</span> <span class="n">feat_pooled</span><span class="p">,</span> <span class="n">offset_pooled</span><span class="p">],</span> <span class="n">cluster_inverse</span>
</code></pre></div></div> <p>Le <code class="language-plaintext highlighter-rouge">cluster_inverse</code> est <strong>crucial</strong> car il permet le <strong>Map Unpooling</strong> plus tard :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># cluster_inverse: (N,) - pour chaque point, son voxel d'appartenance
</span><span class="n">cluster_inverse</span><span class="p">[</span><span class="n">point_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">voxel_id</span>

<span class="c1"># Exemple
</span><span class="n">cluster_inverse</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="c1">#                  ↑─────↑  ↑──↑  ↑────────↑  ↑──────↑
#                  Points du voxel 0, 1, 2, 3
</span></code></pre></div></div> <p>Ce mapping sera réutilisé dans <code class="language-plaintext highlighter-rouge">UnpoolWithSkip</code> pour “dépooler” efficacement !</p> <hr> <h3 id="4-map-unpooling-gratuit">4. Map Unpooling Gratuit</h3> <p>Le <code class="language-plaintext highlighter-rouge">cluster_inverse</code> permet un unpooling <strong>sans calcul</strong> :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PTv1: doit recalculer K-NN pour l'interpolation
</span><span class="n">upsampled</span> <span class="o">=</span> <span class="nf">knn_interpolation</span><span class="p">(</span><span class="n">low_res</span><span class="p">,</span> <span class="n">high_res</span><span class="p">)</span>  <span class="c1"># Coûteux !
</span>
<span class="c1"># PTv2: réutilise le cluster mapping
</span><span class="n">upsampled</span> <span class="o">=</span> <span class="n">feat_low_res</span><span class="p">[</span><span class="n">cluster_inverse</span><span class="p">]</span>  <span class="c1"># Lookup instantané !
</span></code></pre></div></div> <h1 id="unpoolwithskip--map-unpooling-avec-skip-connections">UnpoolWithSkip : Map Unpooling avec Skip Connections</h1> <h2 id="vue-densemble-2">Vue d’ensemble</h2> <p><code class="language-plaintext highlighter-rouge">UnpoolWithSkip</code> est le pendant de <code class="language-plaintext highlighter-rouge">GridPool</code> dans le décodeur, permettant de remonter en résolution tout en fusionnant l’information multi-échelle via les skip connections.</p> <figure> <picture> <img src="/assets/img/poinTransformerv2/unpoolWithSkip.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="problème-avec-k-nn-interpolation-ptv1">Problème avec K-NN Interpolation (PTv1)</h2> <h3 id="algorithme-dinterpolation-ptv1">Algorithme d’Interpolation PTv1</h3> <p>Dans PTv1, pour passer de M points (basse résolution) à N points (haute résolution), on utilise une <strong>interpolation par K-NN</strong> :</p> <h3 id="problèmes-de-linterpolation">Problèmes de l’Interpolation</h3> <p><strong>1. Coût computationnel :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pour chaque point haute résolution N:
#   - Calculer M distances
#   - Trier pour trouver les K plus proches
#   - Calculer la moyenne pondérée
</span>
<span class="n">Complexité</span><span class="p">:</span> <span class="nc">O</span><span class="p">(</span><span class="n">N</span> <span class="err">×</span> <span class="n">M</span> <span class="n">log</span> <span class="n">M</span><span class="p">)</span>

<span class="c1"># Exemple: M=25k, N=100k
</span><span class="n">Opérations</span><span class="p">:</span> <span class="mi">100</span><span class="n">k</span> <span class="err">×</span> <span class="mi">25</span><span class="n">k</span> <span class="err">×</span> <span class="nf">log</span><span class="p">(</span><span class="mi">25</span><span class="n">k</span><span class="p">)</span> <span class="err">≈</span> <span class="mi">35</span> <span class="n">milliards</span> <span class="err">!</span>
</code></pre></div></div> <h2 id="solution--map-unpooling-ptv2">Solution : Map Unpooling (PTv2)</h2> <h3 id="principe--réutilisation-du-cluster-mapping">Principe : Réutilisation du Cluster Mapping</h3> <p>L’idée géniale de PTv2 : <strong>stocker le mapping lors du downsampling</strong> et le <strong>réutiliser lors de l’upsampling</strong> !</p> <p><strong>Rappel du GridPool :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GridPool retourne le cluster_inverse
</span><span class="n">coord_pooled</span><span class="p">,</span> <span class="n">feat_pooled</span><span class="p">,</span> <span class="n">offset_pooled</span><span class="p">,</span> <span class="n">cluster</span> <span class="o">=</span> <span class="nc">GridPool</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>

<span class="c1"># cluster: (N,) - pour chaque point original, son voxel d'appartenance
</span><span class="n">cluster</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="c1">#          └──┬──┘  └─┬─┘  └────┬────┘  └──┬──┘
#          Voxel 0  Voxel 1  Voxel 2   Voxel 3
</span></code></pre></div></div> <p><strong>Map Unpooling :</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pour remonter en résolution, simple indexing !
</span><span class="n">feat_upsampled</span> <span class="o">=</span> <span class="n">feat_pooled</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span>  <span class="c1"># (N, C)
</span>
<span class="c1"># Chaque point récupère les features de son voxel d'origine
</span></code></pre></div></div> <p><strong>C’est tout !</strong> Un simple lookup, complexité <strong>O(1)</strong> par point, donc <strong>O(N)</strong> total.</p> <hr> <h2 id="algorithme-détaillé">Algorithme Détaillé</h2> <h3 id="inputs">Inputs</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Points actuels (basse résolution)
</span><span class="n">coord_low</span><span class="p">:</span> <span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>        <span class="c1"># Positions des voxels
</span><span class="n">feat_low</span><span class="p">:</span> <span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">)</span>     <span class="c1"># Features des voxels
</span><span class="n">offset_low</span><span class="p">:</span> <span class="p">(</span><span class="n">B</span><span class="p">,)</span>

<span class="c1"># Points skip (haute résolution - de l'encodeur)
</span><span class="n">coord_skip</span><span class="p">:</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="c1"># Positions originales
</span><span class="n">feat_skip</span><span class="p">:</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">skip_ch</span><span class="p">)</span>  <span class="c1"># Features originales
</span><span class="n">offset_skip</span><span class="p">:</span> <span class="p">(</span><span class="n">B</span><span class="p">,)</span>

<span class="c1"># Cluster mapping (du GridPool correspondant)
</span><span class="n">cluster</span><span class="p">:</span> <span class="p">(</span><span class="n">N</span><span class="p">,)</span>            <span class="c1"># Pour chaque point, son voxel
</span></code></pre></div></div> <h3 id="étape-1--projection-des-features-basse-résolution">Étape 1 : Projection des Features Basse Résolution</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feat_low_proj</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">feat_low</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm1d</span> <span class="err">→</span> <span class="n">ReLU</span>
<span class="c1"># feat_low_proj: (M, out_ch)
</span></code></pre></div></div> <h3 id="étape-2--map-unpooling">Étape 2 : Map Unpooling</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Lookup direct via cluster
</span><span class="n">feat_mapped</span> <span class="o">=</span> <span class="n">feat_low_proj</span><span class="p">[</span><span class="n">cluster</span><span class="p">]</span>
<span class="c1"># feat_mapped: (N, out_ch)
</span></code></pre></div></div> <p>Chaque point récupère <strong>exactement</strong> les features de son voxel d’origine !</p> <h3 id="étape-3--projection-des-features-skip">Étape 3 : Projection des Features Skip</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feat_skip_proj</span> <span class="o">=</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">feat_skip</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm1d</span> <span class="err">→</span> <span class="n">ReLU</span>
<span class="c1"># feat_skip_proj: (N, out_ch)
</span></code></pre></div></div> <h3 id="étape-4--fusion-skip-connection">Étape 4 : Fusion Skip Connection</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feat_fused</span> <span class="o">=</span> <span class="n">feat_mapped</span> <span class="o">+</span> <span class="n">feat_skip_proj</span>
<span class="c1"># feat_fused: (N, out_ch)
</span></code></pre></div></div> <p><strong>Visualisation :</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Basse résolution (upsampled):        Skip (haute résolution):
    feat_mapped                           feat_skip_proj
         ↓                                      ↓
    [0.2, 0.5, 0.1, 0.8]              [0.3, 0.1, 0.6, 0.2]
         ↓                                      ↓
         └──────────────── + ────────────────┘
                             ↓
                    [0.5, 0.6, 0.7, 1.0]
                         feat_fused
</code></pre></div></div> <h3 id="étape-5--output">Étape 5 : Output</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">return</span> <span class="p">[</span><span class="n">coord_skip</span><span class="p">,</span> <span class="n">feat_fused</span><span class="p">,</span> <span class="n">offset_skip</span><span class="p">]</span>
<span class="c1"># On retourne les coordonnées skip (haute résolution)
# Avec les features fusionnées
</span></code></pre></div></div> <hr> <h2 id="encoder-et-decoder--vue-complète">Encoder et Decoder : Vue Complète</h2> <h3 id="encoder">Encoder</h3> <figure> <picture> <img src="/assets/img/poinTransformerv2/encoder.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Encoder</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
        <span class="c1"># Downsampling + enrichissement features
</span>        <span class="n">points_pooled</span><span class="p">,</span> <span class="n">cluster</span> <span class="o">=</span> <span class="nc">GridPool</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
        
        <span class="c1"># Attention locale sur les voxels
</span>        <span class="n">points_out</span> <span class="o">=</span> <span class="nc">BlockSequence</span><span class="p">(</span><span class="n">points_pooled</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">points_out</span><span class="p">,</span> <span class="n">cluster</span>
</code></pre></div></div> <h3 id="decoder">Decoder</h3> <figure> <picture> <img src="/assets/img/poinTransformerv2/decoder.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Decoder</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">points_low</span><span class="p">,</span> <span class="n">points_skip</span><span class="p">,</span> <span class="n">cluster</span><span class="p">):</span>
        <span class="c1"># Upsampling + fusion skip
</span>        <span class="n">points_up</span> <span class="o">=</span> <span class="nc">UnpoolWithSkip</span><span class="p">(</span><span class="n">points_low</span><span class="p">,</span> <span class="n">points_skip</span><span class="p">,</span> <span class="n">cluster</span><span class="p">)</span>
        
        <span class="c1"># Attention locale sur les points upsampled
</span>        <span class="n">points_out</span> <span class="o">=</span> <span class="nc">BlockSequence</span><span class="p">(</span><span class="n">points_up</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">points_out</span>
</code></pre></div></div> <hr> <h2 id="performance-globale--ptv1-vs-ptv2">Performance Globale : PTv1 vs PTv2</h2> <h3 id="mémoire">Mémoire</h3> <figure> <picture> <img src="/assets/img/poinTransformerv2/ptv2_time_diff.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="précision">Précision</h3> <figure> <picture> <img src="/assets/img/poinTransformerv2/ptv2_s3dis_miou.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <hr> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/pointTransformerV1/">Point Transformer v1: Architecture and Implementation Details</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/batchingPointclouds/">Batching PointClouds</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/multiheadattention/">MultiHead Attention Visualized</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Antoine Ach. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>